{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we perform regression on the cooling load and the result is evaluated statistically. We compare a baseline, a linear regression model and an ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read/prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_compactness</th>\n",
       "      <th>surface_area</th>\n",
       "      <th>wall_area</th>\n",
       "      <th>roof_area</th>\n",
       "      <th>overall_height</th>\n",
       "      <th>orientation</th>\n",
       "      <th>glazing_area</th>\n",
       "      <th>glazing_area_distribution</th>\n",
       "      <th>heating_load</th>\n",
       "      <th>cooling_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>17.88</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.44</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.48</td>\n",
       "      <td>16.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.64</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     relative_compactness  surface_area  wall_area  roof_area  overall_height  \\\n",
       "0                    0.98         514.5      294.0     110.25             7.0   \n",
       "1                    0.98         514.5      294.0     110.25             7.0   \n",
       "2                    0.98         514.5      294.0     110.25             7.0   \n",
       "3                    0.98         514.5      294.0     110.25             7.0   \n",
       "4                    0.90         563.5      318.5     122.50             7.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "763                  0.64         784.0      343.0     220.50             3.5   \n",
       "764                  0.62         808.5      367.5     220.50             3.5   \n",
       "765                  0.62         808.5      367.5     220.50             3.5   \n",
       "766                  0.62         808.5      367.5     220.50             3.5   \n",
       "767                  0.62         808.5      367.5     220.50             3.5   \n",
       "\n",
       "     orientation  glazing_area  glazing_area_distribution  heating_load  \\\n",
       "0              2           0.0                          0         15.55   \n",
       "1              3           0.0                          0         15.55   \n",
       "2              4           0.0                          0         15.55   \n",
       "3              5           0.0                          0         15.55   \n",
       "4              2           0.0                          0         20.84   \n",
       "..           ...           ...                        ...           ...   \n",
       "763            5           0.4                          5         17.88   \n",
       "764            2           0.4                          5         16.54   \n",
       "765            3           0.4                          5         16.44   \n",
       "766            4           0.4                          5         16.48   \n",
       "767            5           0.4                          5         16.64   \n",
       "\n",
       "     cooling_load  \n",
       "0           21.33  \n",
       "1           21.33  \n",
       "2           21.33  \n",
       "3           21.33  \n",
       "4           28.28  \n",
       "..            ...  \n",
       "763         21.40  \n",
       "764         16.88  \n",
       "765         17.11  \n",
       "766         16.61  \n",
       "767         16.03  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_compactness</th>\n",
       "      <th>surface_area</th>\n",
       "      <th>wall_area</th>\n",
       "      <th>roof_area</th>\n",
       "      <th>overall_height</th>\n",
       "      <th>orientation</th>\n",
       "      <th>glazing_area</th>\n",
       "      <th>glazing_area_distribution</th>\n",
       "      <th>heating_load</th>\n",
       "      <th>cooling_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764167</td>\n",
       "      <td>671.708333</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>176.604167</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>2.81250</td>\n",
       "      <td>22.307201</td>\n",
       "      <td>24.587760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105777</td>\n",
       "      <td>88.086116</td>\n",
       "      <td>43.626481</td>\n",
       "      <td>45.165950</td>\n",
       "      <td>1.75114</td>\n",
       "      <td>1.118763</td>\n",
       "      <td>0.133221</td>\n",
       "      <td>1.55096</td>\n",
       "      <td>10.090196</td>\n",
       "      <td>9.513306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.010000</td>\n",
       "      <td>10.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.682500</td>\n",
       "      <td>606.375000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>140.875000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>12.992500</td>\n",
       "      <td>15.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>673.750000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>183.750000</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>18.950000</td>\n",
       "      <td>22.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>741.125000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>31.667500</td>\n",
       "      <td>33.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>43.100000</td>\n",
       "      <td>48.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       relative_compactness  surface_area   wall_area   roof_area  \\\n",
       "count            768.000000    768.000000  768.000000  768.000000   \n",
       "mean               0.764167    671.708333  318.500000  176.604167   \n",
       "std                0.105777     88.086116   43.626481   45.165950   \n",
       "min                0.620000    514.500000  245.000000  110.250000   \n",
       "25%                0.682500    606.375000  294.000000  140.875000   \n",
       "50%                0.750000    673.750000  318.500000  183.750000   \n",
       "75%                0.830000    741.125000  343.000000  220.500000   \n",
       "max                0.980000    808.500000  416.500000  220.500000   \n",
       "\n",
       "       overall_height  orientation  glazing_area  glazing_area_distribution  \\\n",
       "count       768.00000   768.000000    768.000000                  768.00000   \n",
       "mean          5.25000     3.500000      0.234375                    2.81250   \n",
       "std           1.75114     1.118763      0.133221                    1.55096   \n",
       "min           3.50000     2.000000      0.000000                    0.00000   \n",
       "25%           3.50000     2.750000      0.100000                    1.75000   \n",
       "50%           5.25000     3.500000      0.250000                    3.00000   \n",
       "75%           7.00000     4.250000      0.400000                    4.00000   \n",
       "max           7.00000     5.000000      0.400000                    5.00000   \n",
       "\n",
       "       heating_load  cooling_load  \n",
       "count    768.000000    768.000000  \n",
       "mean      22.307201     24.587760  \n",
       "std       10.090196      9.513306  \n",
       "min        6.010000     10.900000  \n",
       "25%       12.992500     15.620000  \n",
       "50%       18.950000     22.080000  \n",
       "75%       31.667500     33.132500  \n",
       "max       43.100000     48.030000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datapath = \"data/\"\n",
    "filename = 'ENB2012_data.csv'\n",
    "df = pd.read_csv(datapath+filename)\n",
    "col_names = ['relative_compactness', 'surface_area', 'wall_area', 'roof_area', 'overall_height', 'orientation', 'glazing_area', 'glazing_area_distribution', 'heating_load', 'cooling_load']\n",
    "df.columns = col_names\n",
    "display(df)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and data\n",
    "y = df['cooling_load']\n",
    "\n",
    "X = df.iloc[: , :8]\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X))\n",
    "X.columns = col_names[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare models: Two-level (nested) cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline: Compute the largest class on the training data, and predict everything in the test data as belonging to that class. \n",
    "<br/>-> corresponding to logistic regression with bias term and no features.\n",
    "\n",
    "For logistic regression: Inner fold is estimating lambda, the complexity controlling parameter (called C in sklearn)\n",
    "\n",
    "For KNN: Inner fold is estimating K, the number of neighbours in the algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "from toolbox_02450 import train_neural_net\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds in inner and outer cross validation\n",
    "K1, K2 = 2, 2\n",
    "\n",
    "# Parameter grids. I.e. what vals to check for optimality in respective model (for inner folds)\n",
    "p_grid_reg = np.power(10., range(-7, 1))\n",
    "p_grid_ann = [32, 64, 128, 256, 512, 1024, 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation fold: 1/2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t88.59754\t0.000390886\n",
      "\t\tFinal loss:\n",
      "\t\t1562\t85.44173\t9.82228e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t85.46414\t3.3029837e-06\n",
      "\t\tFinal loss:\n",
      "\t\t1149\t85.43806\t9.822702e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t792\t85.4321\t9.823387e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t553\t85.42983\t9.823648e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t413\t85.42896\t9.823748e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t289\t85.42954\t9.823681e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t127\t85.4346\t8.930091e-07\n",
      "\n",
      "Crossvalidation fold: 2/2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t96.403175\t0.0002740675\n",
      "\t\tFinal loss:\n",
      "\t\t1463\t93.955215\t9.744285e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t952\t93.94876\t9.744955e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t676\t93.94851\t9.744981e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t452\t93.94684\t9.745155e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t289\t93.94648\t8.9330933e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t176\t93.944664\t9.74538e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t123\t93.94465\t7.309038e-07\n",
      "\n",
      "\tBest loss error: 85.52705383300781 for 1024 number of hidden units\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t153\t89.71432\t3.401641e-07\n",
      "\n",
      "\tBest loss final_loss: 91.07975769042969\n",
      "\n",
      "\n",
      "Crossvalidation fold: 1/2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t96.09622\t0.00040799435\n",
      "\t\tFinal loss:\n",
      "\t\t1531\t92.607544\t9.886089e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t92.61215\t2.389016e-06\n",
      "\t\tFinal loss:\n",
      "\t\t1054\t92.60408\t9.886459e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t709\t92.59996\t9.0629914e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t496\t92.59766\t9.887145e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t363\t92.59493\t8.239531e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t248\t92.5945\t9.887482e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t171\t92.59443\t9.88749e-07\n",
      "\n",
      "Crossvalidation fold: 2/2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t92.40583\t0.0003603445\n",
      "\t\tFinal loss:\n",
      "\t\t1523\t89.144424\t8.5584577e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t945\t89.13325\t9.4154836e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t635\t89.129974\t9.415829e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t443\t89.12968\t9.4158605e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t283\t89.13016\t9.41581e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t190\t89.12843\t8.5599936e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t124\t89.126076\t5.136134e-07\n",
      "\n",
      "\tBest loss error: 92.75470733642578 for 1024 number of hidden units\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t151\t90.899796\t7.5538674e-07\n",
      "\n",
      "\tBest loss final_loss: 90.31088256835938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = {\"outer_fold\": [], \"reg_lambda_i\": [], \"reg_test_error_i\": [], \"ANN_nb_i\": [],\n",
    "       \"ANN_test_error_i\": [], \"baseline_test_error_i\": []}\n",
    "res[\"outer_fold\"] = range(K1)\n",
    "\n",
    "# Define variables for the ANN model\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "max_iter = 10000\n",
    "N, M = X.shape\n",
    "\n",
    "# K-fold CrossValidation with two layers\n",
    "CV = model_selection.KFold(K1, shuffle=True)\n",
    "for k, (train_index, test_index) in enumerate(CV.split(X, y)):\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index, :]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    ### Baseline estimation error ###\n",
    "    dummy = DummyRegressor(strategy='mean')\n",
    "    dummy.fit(X_train, y_train)\n",
    "    res['baseline_test_error_i'].append(\n",
    "        mean_squared_error(dummy.predict(X_test), y_test))\n",
    "\n",
    "    cv_inner = model_selection.KFold(K2, shuffle=True)\n",
    "\n",
    "    ### Ridge regression ###\n",
    "    ridge_model = RidgeCV(alphas=p_grid_reg, cv=cv_inner,\n",
    "                          scoring='neg_mean_absolute_error').fit(X_train, y_train)\n",
    "    best_param_reg = ridge_model.alpha_\n",
    "    y_pred_reg = ridge_model.predict(X_test)\n",
    "    err_reg = mean_squared_error(y_test, y_pred_reg)\n",
    "    res[\"reg_lambda_i\"].append(best_param_reg)\n",
    "    res[\"reg_test_error_i\"].append(err_reg)\n",
    "\n",
    "    ### ANN inner cross validation ###\n",
    "    # Initializing test error matrix\n",
    "    S = len(p_grid_ann)\n",
    "    Error_test = np.zeros((S, K2))\n",
    "    # K-fold cross-validation for model selection\n",
    "    for k, (train_index_inner, test_index_inner) in enumerate(cv_inner.split(X_train, y_train)):\n",
    "        print('\\nCrossvalidation fold: {0}/{1}'.format(k+1, K2))\n",
    "\n",
    "        # Extract training and test set for current CV fold,\n",
    "        # and convert them to PyTorch tensors\n",
    "        X_train_inner = torch.Tensor(X_train.iloc[train_index_inner, :].values)\n",
    "        y_train_inner = torch.Tensor(y_train.iloc[train_index_inner].values)\n",
    "        X_test_inner = torch.Tensor(X_train.iloc[test_index_inner, :].values)\n",
    "        y_test_inner = torch.Tensor(y_train.iloc[test_index_inner].values)\n",
    "\n",
    "        # Compute the error for each number of hidden unit\n",
    "        for i, n_hidden_units in enumerate(p_grid_ann):\n",
    "\n",
    "            def model(): return torch.nn.Sequential(\n",
    "                # M features to H hiden units\n",
    "                torch.nn.Linear(M, n_hidden_units),\n",
    "                # 1st transfer function, either Tanh or ReLU:\n",
    "                torch.nn.Tanh(),  # torch.nn.ReLU(),\n",
    "                # H hidden units to 1 output neuron\n",
    "                torch.nn.Linear(n_hidden_units, 1)\n",
    "            )\n",
    "\n",
    "            net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                               loss_fn,\n",
    "                                                               X=X_train_inner,\n",
    "                                                               y=y_train_inner,\n",
    "                                                               n_replicates=1,\n",
    "                                                               max_iter=max_iter)\n",
    "\n",
    "            y_test_pred_ann = net(torch.Tensor(X_test_inner))\n",
    "            err_ann_inner = loss_fn(y_test_inner, y_test_pred_ann)\n",
    "            Error_test[i, k] = err_ann_inner\n",
    "\n",
    "    # Find the best number of hidden unit\n",
    "    generalization_error = Error_test.mean(1)\n",
    "    best_n_hidden_units = p_grid_ann[np.argmin(generalization_error)]\n",
    "\n",
    "    print(\n",
    "        f'\\n\\tBest loss error: {err_ann_inner} for {best_n_hidden_units} number of hidden units\\n')\n",
    "\n",
    "    # Compute the final error\n",
    "    def model(): return torch.nn.Sequential(\n",
    "        # M features to H hiden units\n",
    "        torch.nn.Linear(M, best_n_hidden_units),\n",
    "        # 1st transfer function, either Tanh or ReLU:\n",
    "        torch.nn.Tanh(),  # torch.nn.ReLU(),\n",
    "        # H hidden units to 1 output neuron\n",
    "        torch.nn.Linear(best_n_hidden_units, 1)\n",
    "    )\n",
    "    net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                       loss_fn,\n",
    "                                                       X=torch.Tensor(\n",
    "                                                           X_train.values),\n",
    "                                                       y=torch.Tensor(\n",
    "                                                           y_train.values),\n",
    "                                                       n_replicates=1,\n",
    "                                                       max_iter=max_iter)\n",
    "    y_pred_ann = net(torch.Tensor(X_test.values))\n",
    "    err_ann = loss_fn(torch.Tensor(y_test.values), y_test_pred_ann)\n",
    "    print('\\n\\tBest loss final_loss: {}\\n'.format(err_ann))\n",
    "\n",
    "    res[\"ANN_nb_i\"].append(best_n_hidden_units)\n",
    "    res[\"ANN_test_error_i\"].append(float(err_ann))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outer_fold</th>\n",
       "      <th>reg_lambda_i</th>\n",
       "      <th>reg_test_error_i</th>\n",
       "      <th>ANN_nb_i</th>\n",
       "      <th>ANN_test_error_i</th>\n",
       "      <th>baseline_test_error_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.753393</td>\n",
       "      <td>1024</td>\n",
       "      <td>91.079758</td>\n",
       "      <td>91.224118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.795240</td>\n",
       "      <td>1024</td>\n",
       "      <td>90.310883</td>\n",
       "      <td>90.035563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outer_fold  reg_lambda_i  reg_test_error_i  ANN_nb_i  ANN_test_error_i  \\\n",
       "0           0           0.1          9.753393      1024         91.079758   \n",
       "1           1           0.1         10.795240      1024         90.310883   \n",
       "\n",
       "   baseline_test_error_i  \n",
       "0              91.224118  \n",
       "1              90.035563  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame.from_dict(data=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa2052e9a08f0910284e2d7e8b5954f4401c8e958dc175eb29fb1cae388f6ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
